{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter Grader\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![data-x](https://raw.githubusercontent.com/afo/data-x-plaksha/master/imgsource/dx_logo.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### NAME: Haojuan He\n",
    "\n",
    "#### STUDENT ID: 3033721461\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP for Sentiment Analysis on IMDB Movie Reviews\n",
    "\n",
    "In this assignment we will be exploring tools for Natural Language Processing (NLP). Our task is sentiment analysis for movie reviews and in that context we will touch upon multiple areas:\n",
    "\n",
    "- Feature engineering\n",
    "- Bag of words modeling\n",
    "- Word2Vec modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/haojuanhe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/haojuanhe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/haojuanhe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/haojuanhe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import Beautiful Soup, NumPy and Pandas, etc\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    " \n",
    "# download NLTK classifiers - these are cached locally on your machine\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# import ml classifiers\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "from nltk.stem import PorterStemmer     # parsing/stemmer\n",
    "from nltk.tag import pos_tag            # parts-of-speech tagging\n",
    "from nltk.corpus import wordnet         # sentiment scores\n",
    "from nltk.stem import WordNetLemmatizer # stem and context\n",
    "from nltk.corpus import stopwords       # stopwords\n",
    "from nltk.util import ngrams            # ngram iterator\n",
    "\n",
    "# import word2vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "___\n",
    "\n",
    "### Data Description\n",
    ">Data source: https://www.kaggle.com/c/word2vec-nlp-tutorial/data (originally from [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/))<br>\n",
    ">\n",
    ">Data Description:<br><br>\n",
    ">We will be using Kaggle's **Bag of Words Meets Bags of Popcorn** dataset to explore [IMBD](https://www.imdb.com/) movie review data. This dataset in included with the zip file distribution of your homework. Labeled training dataset consists of 25,000 IMDB movie reviews. The sentiment of the reviews are binary, meaning an IMDB rating < 5 results in a sentiment score of 0, and a rating >=7 have a sentiment score of 1 (no reviews with score 5 or 6 are included in the analysis). No individual movie has more than 30 reviews. The training data set is constructed in a balanced way so that there are an equal number of positive and negative reviews for each movie. There is also an unlabeled test set with 25,000 IMDB movie reviews. We don't use this for testing, but we do use it to improve unsupervised learning.\n",
    ">\n",
    ">Data Sets:<br>\n",
    ">* ```labeledTrainData.tsv``` --> The labeled training set. The file is tab-delimited and has a header row followed by 25,000 rows containing an id (numerical), sentiment (categorical), and text for each review (textual).<br>\n",
    ">* ```testData.tsv``` --> The unlabeled test set. 25,000 rows containing an id (numerical), and text for each review (textual). \n",
    ">\n",
    "> Further Reading:<br>\n",
    "> \n",
    "> * [Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).](http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "## Preparing data for classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided the function `review_cleaner` to preprocess reviews. Here is an overview of what it does:\n",
    "\n",
    "> - Removes HTML tags (using beautifulsoup)\n",
    "> - Extract emoticons (emotion symbols, aka smileys :D )\n",
    "> - Removes non-letters (using regular expression)\n",
    "> - Converts all words to lowercase letters and tokenizes them (using .split() method on the review strings, so that every word in the review is an element in a list)\n",
    "> - Removes all the English stopwords from the list of movie review words\n",
    "> - Applies either stemming or lemmatization, as indicated by the arguments\n",
    "> - Join the words back into one string seperated by space, append the emoticons to the end\n",
    "\n",
    "Note that you do not need to make any changes to `review_cleaner`. We will explore some examples of the cleaning process below.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def review_cleaner(review, lemmatize=True, stem=False):\n",
    "    '''\n",
    "        Clean and preprocess a review.\n",
    "            1. Remove HTML tags\n",
    "            2. Extract emoticons\n",
    "            3. Use regex to remove all special characters (only keep letters)\n",
    "            4. Make strings to lower case and tokenize / word split reviews\n",
    "            5. Remove English stopwords\n",
    "            6. Lemmatize\n",
    "            7. Rejoin to one string\n",
    "        \n",
    "        @review (type:str) is an unprocessed review string\n",
    "        @return (type:str) is a 6-step preprocessed review string\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "    if lemmatize == True and stem == True:\n",
    "        raise RuntimeError(\"May not pass both lemmatize and stem flags\")\n",
    "\n",
    "    #1. Remove HTML tags\n",
    "    review = bs.BeautifulSoup(review).text    \n",
    "\n",
    "    #2. Use regex to find emoticons\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
    "\n",
    "    #3. Remove punctuation\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \",review)\n",
    "\n",
    "    #4. Tokenize into words (all lower case)\n",
    "    review = review.lower().split()\n",
    "\n",
    "    #5. Remove stopwords, Lemmatize, Stem\n",
    "    clean_review=[]\n",
    "    for word in review:\n",
    "        if word not in eng_stopwords:\n",
    "            if lemmatize is True:\n",
    "                word=wnl.lemmatize(word)\n",
    "            elif stem is True:\n",
    "                if word == 'oed':\n",
    "                    continue\n",
    "                word=ps.stem(word)\n",
    "            clean_review.append(word)\n",
    "\n",
    "    #6. Join the review to one sentence\n",
    "    review_processed = ' '.join(clean_review+emoticons)\n",
    "    \n",
    "    return review_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "To make things interesting, everyone gets to analyze a different review. Set `seed_value` to your favorite number, your name, or whatever else you'd like.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0_set_seed\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "seed_value = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0_set_seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Dull, cheap sci-fi thriller, made with an almost total lack of conviction (a control room full of computers and other devices used to receive and decipher messages from outer space is run by only ONE MAN, and is VERY poorly guarded at night), and full of campy sound effects. Christopher Lee is not only wasted, but he also gives one of his few \\\"I'm here strictly for the money\\\" performances. (*1/2)\"\n"
     ]
    }
   ],
   "source": [
    "# Print out a cleaned version of the randomly selected review\n",
    "my_review_id = int(hashlib.md5(str(seed_value).encode(\"utf-8\")).hexdigest()[:8], 16) % len(train.index)\n",
    "my_review = train.iloc[my_review_id][\"review\"]\n",
    "print(my_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Find the stopwords\n",
    "\n",
    "By manual inspection, find the first 5 stopwords in your chosen review. It might seem easier to write the code to do this, but the point of the exercise is to understand what the algorithm is doing.\n",
    "\n",
    "First review the list of stopwords below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i me my myself we our ours ourselves you you're you've you'll you'd your yours yourself yourselves he him his himself she she's her hers herself it it's its itself they them their theirs themselves what which who whom this that that'll these those am is are was were be been being have has had having do does did doing a an the and but if or because as until while of at by for with about against between into through during before after above below to from up down in out on off over under again further then once here there when where why how all any both each few more most other some such no nor not only own same so than too very s t can will just don don't should should've now d ll m o re ve y ain aren aren't couldn couldn't didn didn't doesn doesn't hadn hadn't hasn hasn't haven haven't isn isn't ma mightn mightn't mustn mustn't needn needn't shan shan't shouldn shouldn't wasn wasn't weren weren't won won't wouldn wouldn't\n"
     ]
    }
   ],
   "source": [
    "# See what the stopwords are\n",
    "print(\" \".join(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Inspect the review and look for the 5 first stopwords. Store them in `first_5_stopwords` in the order in which they appear in the review.\n",
    "\n",
    "e.g., \n",
    "```\n",
    "first_5_stopwords = ['having', 'the', 'to', 'some', 'of']\n",
    "```\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_stopwords_type\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with', 'an', 'of', 'a', 'of']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "first_5_stopwords = []\n",
    "import re\n",
    "for i in my_review.split(\" \"):\n",
    "    i = re.sub(r\"[^a-zA-Z0-9]\", \"\", i).lower()\n",
    "    if (len(first_5_stopwords)<5) & (i in stopwords.words('english')):\n",
    "        #print(i)\n",
    "        first_5_stopwords.append(i)\n",
    "    elif len(first_5_stopwords) >= 5:\n",
    "        break;\n",
    "first_5_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_stopwords_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_stopwords_length\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q1_stopwords_length.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q1_stopwords_length.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_stopwords_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_stopwords_match\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_stopwords_match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Lemmatization\n",
    "\n",
    "Lemmatization allows grouping of common forms of a word.\n",
    "\n",
    "Here are some examples of lemmatization:\n",
    "* images -> image\n",
    "* waxworks -> waxwork\n",
    "* sweets -> sweet\n",
    "\n",
    "By manual inspection, find the first 3 words in `my_review` that are lemmatized. Store them in `first_3_lemmatized` in the order in which they appear in the review.\n",
    "\n",
    "E.g.:\n",
    "```\n",
    "first_3_lemmatized = ['images', 'waxworks', 'sweets']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Dull, cheap sci-fi thriller, made with an almost total lack of conviction (a control room full of computers and other devices used to receive and decipher messages from outer space is run by only ONE MAN, and is VERY poorly guarded at night), and full of campy sound effects. Christopher Lee is not only wasted, but he also gives one of his few \\\\\"I\\'m here strictly for the money\\\\\" performances. (*1/2)\"'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_lemmatization_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization examples:\n",
      "computers -> computer\n",
      "devices -> device\n",
      "messages -> message\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "first_3_lemmatized = ['computers','devices','messages']\n",
    "\n",
    "print(\"Lemmatization examples:\")\n",
    "for w in first_3_lemmatized:\n",
    "    print(\"{} -> {}\".format(w, wnl.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q2_lemmatization_type.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q2_lemmatization_type.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_lemmatization_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_lemmatization_length\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q2_lemmatization_length.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q2_lemmatization_length.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_lemmatization_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_lemmatization_match\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_lemmatization_match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3 - Stemming\n",
    "\n",
    "Lemmatization allows grouping of common forms of a word.\n",
    "\n",
    "Here are some examples of stemming:\n",
    "* nonsense -> nonsens\n",
    "* investigates -> investig\n",
    "* disappearance -> disappear\n",
    "\n",
    "By manual inspection, find the first 3 words in `my_review` that are modified by stemming. Store them in `first_3_stemmed` in the order in which they appear in the review.\n",
    "\n",
    "E.g.:\n",
    "```\n",
    "first_3_stemmed = ['nonsense', 'investigates', 'disappearance']\n",
    "```\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_stemming_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conviction', 'computers', 'devices']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_review\n",
    "first_5_stopwords_l = []\n",
    "#import re\n",
    "for i in my_review.split(\" \"):\n",
    "    i = re.sub(r\"[^a-zA-Z0-9]\", \"\", i).lower()\n",
    "    if (len(first_5_stopwords_l)<3) and (i not in set(stopwords.words(\"english\"))) and not (ps.stem(i)) == i:\n",
    "#        #print(i)\n",
    "        first_5_stopwords_l.append(i)\n",
    "    elif len(first_5_stopwords_l) >= 3:\n",
    "        break;\n",
    "first_5_stopwords_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming examples:\n",
      "conviction -> convict\n",
      "computers -> comput\n",
      "devices -> devic\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "first_3_stemmed = ['conviction','computers','devices']\n",
    "\n",
    "print(\"Stemming examples:\")\n",
    "for w in first_3_stemmed:\n",
    "    print(\"{} -> {}\".format(w, ps.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q3_stemming_type.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q3_stemming_type.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_stemming_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_stemming_length\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q3_stemming_length.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q3_stemming_length.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_stemming_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_stemming_match\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q3_stemming_match.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q3_stemming_match.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_stemming_match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "## Part II: Train and validate a sentiment analysis model using a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we have written the code to train the classifier for you. Your task will be to explore its performance characteristics with your own movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We vectorize the text using a bag of words model\n",
    "def get_vectorizer(ngram, max_features):\n",
    "    return CountVectorizer(ngram_range=(1, ngram),\n",
    "                             analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = review_cleaner,\n",
    "                             stop_words = None, \n",
    "                             max_features = max_features)\n",
    "\n",
    "# Model training\n",
    "def train_predict_sentiment(reviews, vectorizer, y=train[\"sentiment\"], ngram=1, max_features=1000, model_random_state=123):\n",
    "    '''\n",
    "        This function will:\n",
    "            1. split data into train and test set.\n",
    "            2. get n-gram counts from cleaned reviews \n",
    "            3. train a random forest model using train n-gram counts and y (labels)\n",
    "            4. test the model on your test split\n",
    "            5. print accuracy of sentiment prediction on test and training data\n",
    "            6. print confusion matrix on test data results\n",
    "\n",
    "            To change n-gram type, set value of ngram argument\n",
    "            To change the number of features you want the countvectorizer to generate, set the value of max_features argument\n",
    "            \n",
    "            @cleaned_review (type:str) is preprocessed string from review_cleaner()\n",
    "            @return none\n",
    "    '''\n",
    "\n",
    "    print(\"Creating the bag of words model!\\n\")\n",
    "    \n",
    "    # train / test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reviews, y, random_state=0, test_size=.2)\n",
    "\n",
    "    # Then we use fit_transform() to fit the model / learn the vocabulary,\n",
    "    # then transform the data into feature vectors.\n",
    "    # The input should be a list of strings. .toarray() converts to a numpy array\n",
    "    \n",
    "    train_bag = vectorizer.fit_transform(X_train)\n",
    "    if not isinstance(train_bag, np.ndarray):\n",
    "        train_bag = train_bag.toarray()\n",
    "    test_bag = vectorizer.transform(X_test)\n",
    "    if not isinstance(test_bag, np.ndarray):\n",
    "        test_bag = test_bag.toarray()\n",
    "\n",
    "    print(\"Training the random forest classifier!\\n\")\n",
    "    # Initialize a Random Forest classifier with 50 trees\n",
    "    forest = RandomForestClassifier(n_estimators = 50, random_state = model_random_state) \n",
    "\n",
    "    # Fit the forest to the training set, using the bag of words as \n",
    "    # features and the sentiment labels as the target variable\n",
    "    forest = forest.fit(train_bag, y_train)\n",
    "\n",
    "    # predict\n",
    "    train_predictions = forest.predict(train_bag)\n",
    "    test_predictions = forest.predict(test_bag)\n",
    "    \n",
    "    # validation\n",
    "    train_acc = metrics.accuracy_score(y_train, train_predictions)\n",
    "    valid_acc = metrics.accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    print(\" The training accuracy is: \", train_acc, \"\\n\", \"The validation accuracy is: \", valid_acc)\n",
    "    print()\n",
    "    print('CONFUSION MATRIX:')\n",
    "    print('         Predicted')\n",
    "    print('          neg pos')\n",
    "    print(' Actual')\n",
    "    c=confusion_matrix(y_test, test_predictions)\n",
    "    print('     neg  ',c[0])\n",
    "    print('     pos  ',c[1])\n",
    "\n",
    "    return forest\n",
    "\n",
    "# Print out the top features\n",
    "def top_features(forest, vectorizer, n):\n",
    "    #Extract feature importance\n",
    "    print('\\nTOP TEN IMPORTANT FEATURES:')\n",
    "    feature_text = vectorizer.get_feature_names().copy()\n",
    "    feature_importance = forest.feature_importances_.copy()\n",
    "    \n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    top_n_ind = indices[:n]\n",
    "    top_n = list([vectorizer.get_feature_names()[ind] for ind in top_n_ind])\n",
    "    \n",
    "    print(top_n)\n",
    "\n",
    "# Print out whether the prediction is accurate\n",
    "def check_prediction(model, vectorizer, review, expected):\n",
    "    prediction = model.predict(vectorizer.transform([review]))[0]\n",
    "    sentiment = \"üëç\" if prediction else \"üëé\"\n",
    "    correct = \"\\x1b[92mcorrect\\x1b[0m\" if prediction == expected else \"\\x1b[31mincorrect\\x1b[0m\"\n",
    "    print(\"{} ‚ü∂ {} {}\".format(review, sentiment, correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Train Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words model!\n",
      "\n",
      "Training the random forest classifier!\n",
      "\n",
      " The training accuracy is:  0.9999 \n",
      " The validation accuracy is:  0.7184\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "         Predicted\n",
      "          neg pos\n",
      " Actual\n",
      "     neg   [1853  695]\n",
      "     pos   [ 713 1739]\n",
      "\n",
      "TOP TEN IMPORTANT FEATURES:\n",
      "['bad', 'great', 'movie', 'film', 'best', 'one', 'even', 'like', 'nothing', 'love', 'good', 'well', 'plot', 'story', 'time', 'would', 'also', 'life', 'acting', 'character']\n"
     ]
    }
   ],
   "source": [
    "# Train RFC model\n",
    "vectorizer = get_vectorizer(ngram=1, max_features=100)\n",
    "forest_model = train_predict_sentiment(reviews=train[\"review\"], vectorizer=vectorizer, y=train[\"sentiment\"])\n",
    "top_features(forest_model, vectorizer, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4 - Construct a positive sentiment review\n",
    "\n",
    "Think of a movie that you like and write a review for it. Store as a string in `good_review`. If the model doesn't give a positive prediction for your review iterate on it until it does.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_positive_review_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like the movie the white chicks. I have watch it many times and it still makes me laugh. ‚ü∂ üëç \u001b[92mcorrect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "good_review = 'I really like the movie the white chicks. I have watch it many times and it still makes me laugh.'\n",
    "check_prediction(forest_model, vectorizer, good_review, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q4_positive_review_type.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q4_positive_review_type.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_positive_review_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_positive_review_prediction\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_positive_review_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5 - Construct a negative sentiment review\n",
    "\n",
    "Think of a movie that you like and write a review for it. Store as a string in `bad_review`. If the model doesn't give a negative prediction for your review iterate on it until it does.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_negative_review_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really don't like the movie Batman v Superman: Dawn of Justice. It is very confusing and I am very lost in the movie. ‚ü∂ üëé \u001b[92mcorrect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "bad_review = \"I really don't like the movie Batman v Superman: Dawn of Justice. It is very confusing and I am very lost in the movie.\"\n",
    "check_prediction(forest_model, vectorizer, bad_review, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q5_negative_review_type.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q5_negative_review_type.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5_negative_review_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_negative_review_prediction\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5_negative_review_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6 - Construct a misclassified negative sentiment review\n",
    "\n",
    "Now try to write a review that you view as negative but the model views as positive. Iterate and experiment as necessary and store it as a string  `bad_review_error`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_misclassified_review_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lots of people like the movie Superman series but I disagree. I don't feel connected to the character and often disagree with his opinion. ‚ü∂ üëç \u001b[31mincorrect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "bad_review_error = \"Lots of people like the movie Superman series but I disagree. I don't feel connected to the character and often disagree with his opinion.\"\n",
    "check_prediction(forest_model, vectorizer, bad_review_error, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>1 of 1 tests passed</p>\n",
       "        \n",
       "        <p> <strong>Tests passed:</strong>\n",
       "             tests/q6_misclassified_review_type.py \n",
       "        </p>\n",
       "        \n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    \n",
       "    1 of 1 tests passed\n",
       "    \n",
       "    Tests passed:  tests/q6_misclassified_review_type.py \n",
       "    \n",
       "    \n",
       "    "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6_misclassified_review_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_misclasified_review_prediction\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6_misclasified_review_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sentences=[utils.simple_preprocess(review) for review in train['review']], size=100, seed=123, workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 - Explain Word2Vec similarity on display below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actor', 0.7575228214263916),\n",
       " ('singer', 0.7029047012329102),\n",
       " ('performance', 0.6855248808860779),\n",
       " ('role', 0.6842530965805054),\n",
       " ('performer', 0.6733698844909668),\n",
       " ('comedienne', 0.606367290019989),\n",
       " ('accent', 0.5927063226699829),\n",
       " ('dancer', 0.5887244939804077),\n",
       " ('lady', 0.5706830620765686),\n",
       " ('emma', 0.5658652782440186)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['actress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Pick one word similar to 'actress' and explain why it appears\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_word2vec_similar_actress\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"performer\" is similar to the word \"actress\". They are similar because both words are used to describe people who work in the entertainment industry and who's job is to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 - Explain Word2Vec comparison on display below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('herself', 0.4551050662994385),\n",
       " ('sabrina', 0.4506102502346039),\n",
       " ('queen', 0.44201284646987915),\n",
       " ('her', 0.43203961849212646),\n",
       " ('woman', 0.4263123869895935),\n",
       " ('beautiful', 0.41950130462646484),\n",
       " ('victoria', 0.3826228082180023),\n",
       " ('stanwyck', 0.38227301836013794),\n",
       " ('whore', 0.38069406151771545),\n",
       " ('alicia', 0.37620246410369873)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['actress'], negative=['actor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Pick one word similar to 'actress' and dissimilar to 'actor' explain why it appears\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_word2vec_similar_actress_dissimilar_actor\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Women' is similar to 'actress' and dissimilar to 'actor' because both 'women' and 'actress' are used to refer to someone who is female while 'actor' is used to describe someone in the opposite gender (male)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_feature_vecs(reviews, model):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one \n",
    "\n",
    "    \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    reviewFeatureVecs = []\n",
    "    # Loop through the reviews\n",
    "    for counter, review in enumerate(reviews):\n",
    "        \n",
    "        # Print a status message every 5000th review\n",
    "        if (counter + 1) % 5000. == 0.:\n",
    "            print(\"Review %d of %d\" % (counter + 1, len(reviews)))\n",
    "\n",
    "        # Function to average all of the word vectors in a given paragraph\n",
    "        featureVec = []\n",
    "\n",
    "        # Loop over each word in the review and, if it is in the model's\n",
    "        # vocaublary, add its feature vector to the total\n",
    "        for n,word in enumerate(utils.simple_preprocess(review)):\n",
    "            if word in index2word_set: \n",
    "                featureVec.append(model.wv[word])\n",
    "\n",
    "        # Average the word vectors for a \n",
    "        featureVec = np.mean(featureVec, axis=0).reshape(1,-1)\n",
    "\n",
    "        reviewFeatureVecs.append(featureVec)\n",
    "\n",
    "    return np.concatenate(reviewFeatureVecs, axis=0)\n",
    "\n",
    "w2v_vectorizer = FunctionTransformer(lambda x: get_avg_feature_vecs(x, w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words model!\n",
      "\n",
      "Review 5000 of 20000\n",
      "Review 10000 of 20000\n",
      "Review 15000 of 20000\n",
      "Review 20000 of 20000\n",
      "Review 5000 of 5000\n",
      "Training the random forest classifier!\n",
      "\n",
      " The training accuracy is:  0.99995 \n",
      " The validation accuracy is:  0.8038\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "         Predicted\n",
      "          neg pos\n",
      " Actual\n",
      "     neg   [2046  502]\n",
      "     pos   [ 479 1973]\n"
     ]
    }
   ],
   "source": [
    "v2v_forest_model = train_predict_sentiment(reviews=train[\"review\"], vectorizer=w2v_vectorizer, y=train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 9 - compare Word2Vec to Bag of Words\n",
    "\n",
    "Comment on how Word2Vec compares with the Bag of Words Model. Please use the template below for your answer\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q9_word2vec_comparison\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Complete answers below*:\n",
    "\n",
    "* **Is it an improvement?**\n",
    "\n",
    " Word2Vec is an improvement from Bag of Words as we can see from the increasing accruacy of the validation ratio.\n",
    "\n",
    "* **How significant is the difference?**\n",
    "\n",
    " Although the training accuracy is very similar for the two model and even lower in Word2Vec, we can see a significance improvement in the validation accuracy in for Word2Vec by almost 10 percent.\n",
    "\n",
    "* **Is this a fair and meaningful comparision? Why or why not?**\n",
    " \n",
    " This a fair and meaningful comparision. It is fair because it is comparing two model with identical purpose, also those two models use the same training set and testing set so they are given the same amount of information to perfect the model. It is meaningful as those two models are very useful in real life, especially in rating and consumer support field. It is meaningful as it proves that keeping meaning of words help reading sentiments.\n",
    "\n",
    "* **What other experiments might you run to further compare?**\n",
    " \n",
    " I would want to run the model with some other NLP models that were commonly used in other field. For example, how google mail use a classifier to seperate spam email. Since both model are doing language processing but Word2Vec is handling sentiment while Spam classifer is handling usefulness of the content, I think it will be interesting to compare this two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Add more training data\n",
    "\n",
    "You will now try to further improve the performance of the Word2Vec model by enhancing it with unlabeled data. \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10_word2vec_train_more\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unlabeled test data set\n",
    "more_training_data = pd.read_csv(\"testData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 5 rows\n",
    "more_training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model so that it learns from the reviews in more_training_data.\n",
    "# This involves two steps: 1/ updating the vocabulary, 2/ training the model.\n",
    "# Be sure to preprocess the reviews. Your code should modify and update w2v_model\n",
    "\n",
    "# Your code here\n",
    "updated = np.concatenate((np.array(train['review']), np.array(more_training_data['review'])), axis=0)\n",
    "w2v_model = Word2Vec(sentences=[utils.simple_preprocess(review) for review in updated], size=100, seed=123, workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words model!\n",
      "\n",
      "Review 5000 of 20000\n",
      "Review 10000 of 20000\n",
      "Review 15000 of 20000\n",
      "Review 20000 of 20000\n",
      "Review 5000 of 5000\n",
      "Training the random forest classifier!\n",
      "\n",
      " The training accuracy is:  1.0 \n",
      " The validation accuracy is:  0.8084\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "         Predicted\n",
      "          neg pos\n",
      " Actual\n",
      "     neg   [2057  491]\n",
      "     pos   [ 467 1985]\n"
     ]
    }
   ],
   "source": [
    "w2v_forest_model = train_predict_sentiment(reviews=train[\"review\"], vectorizer=FunctionTransformer(lambda x: get_avg_feature_vecs(x, w2v_model)), y=train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 - Comment on the impact of more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Complete answers below*:\n",
    "\n",
    "* **Did adding more training data improve the model?**\n",
    "\n",
    "Adding more training data had a both sided effect on the model. On one hand it did improve the training accuracy, however the validation accuracy decrease. Overall I think adding more training data did not improve the model as it overffit the model and cause the validation accuracy to decrease.\n",
    "\n",
    "* **How significant is the difference?**\n",
    "\n",
    "The difference is not significant, however we do see a minor decrease in the validation accuracy and we see the training accuracy increase to 1. So even though the difference is not significcant we can tell that adding more training data overffit the model and thus make the predicition less accurate for untrained data.\n",
    "\n",
    "* **Why could one expect a model to improve even when provided with unlabeled data?**\n",
    "\n",
    "I don't believe the model is going to improved much with unlabeled data, but I do predict there will be minor increase with the prediction. Because the Word2Vec will add more unseen words and assigned unique value to it. As a result it's even the random words is going to increase some from of improvement, even though it's not much, the model is able to see more words and as a result, some improvement in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Prediction Analysis\n",
    "\n",
    "Check to see how the Word2Vec model works on the reviews that you wrote previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like the movie the white chicks. I have watch it many times and it still makes me laugh. ‚ü∂ üëç \u001b[92mcorrect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "check_prediction(w2v_forest_model, w2v_vectorizer, good_review, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really don't like the movie Batman v Superman: Dawn of Justice. It is very confusing and I am very lost in the movie. ‚ü∂ üëç \u001b[31mincorrect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "check_prediction(v2v_forest_model, w2v_vectorizer, bad_review, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Bag of Words:\n",
      "Lots of people like the movie Superman series but I disagree. I don't feel connected to the character and often disagree with his opinion. ‚ü∂ üëç \u001b[31mincorrect\u001b[0m\n",
      "With Word2Vec:\n",
      "Lots of people like the movie Superman series but I disagree. I don't feel connected to the character and often disagree with his opinion. ‚ü∂ üëé \u001b[92mcorrect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"With Bag of Words:\")\n",
    "check_prediction(forest_model, vectorizer, bad_review_error, 0)\n",
    "\n",
    "print(\"With Word2Vec:\")\n",
    "check_prediction(v2v_forest_model, w2v_vectorizer, bad_review_error, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 11 - how does the Word2Vec model compare to Bag of Words?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q11_word2vec_comment\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "Just comment, don't change your reviews to achieve a particular outcome.\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Complete answers below:*\n",
    "\n",
    "* **Is your positive review classified correctly by Word2Vec?**\n",
    "\n",
    "Yes.\n",
    "\n",
    "* **Is your negative review classified correctly by Word2Vec?**\n",
    "\n",
    "No. Even though there are some strong indications words in the sentences, the classifier still miss classify it.\n",
    "\n",
    "* **Is your negative review misclassified by Bag of Words now classified correctly by Word2Vec?**\n",
    "\n",
    "Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 12 - create a review where the models disagree\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q12_word2vec_split_decision_exists\n",
    "manual: false\n",
    "points: 0\n",
    "-->\n",
    "\n",
    "If your originally misclassified negative review was properly classified by Word2Vec you may use it to answer this question.\n",
    "If not, construct some other review that is properly classified by one model and improperly classified by the other model. Store that review as a string in `split_prediction`. Store the expected prediction in `split_prediction_expected` as 1 for positive sentiment or 0 for negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Bag of Words:\n",
      "Lots of people like the movie Superman series but I disagree. I don't feel connected to the character and often disagree with his opinion. ‚ü∂ üëç \u001b[31mincorrect\u001b[0m\n",
      "With Word2Vec:\n",
      "Lots of people like the movie Superman series but I disagree. I don't feel connected to the character and often disagree with his opinion. ‚ü∂ üëé \u001b[92mcorrect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "split_prediction = \"Lots of people like the movie Superman series but I disagree. I don't feel connected to the character and often disagree with his opinion.\"\n",
    "split_prediction_expected = 0\n",
    "\n",
    "print(\"With Bag of Words:\")\n",
    "check_prediction(forest_model, vectorizer, split_prediction, split_prediction_expected)\n",
    "\n",
    "print(\"With Word2Vec:\")\n",
    "check_prediction(v2v_forest_model, w2v_vectorizer, split_prediction, split_prediction_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q12_word2vec_split_decision_defined\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q12_word2vec_split_decision_defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q12_word2vec_split_decision_predict\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q12_word2vec_split_decision_predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 6 EXPORTED QUESTIONS -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
